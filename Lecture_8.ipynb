{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VNIH93hD-Ya"
   },
   "source": [
    "# Lecture 8 - PyTorch\n",
    "\n",
    "This will be the final lecture, today we will first have a brief introduction of deep learning, then we will look at some basics of using PyTorch to implement some simple models in deep learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-fCZYu2D-Yc"
   },
   "source": [
    "## Deep Learning Libraries\n",
    "\n",
    "There are many deep learning libraries available, the most common ones for python are\n",
    "\n",
    "- TensorFlow, Keras\n",
    "- PyTorch\n",
    "\n",
    "Working with tensorflow requires going into lot of details of the contruction of the computation graph, whereas Keras is a higher level interface for tensorflow. Tensorflow is very popular in the industry and good for production code.\n",
    "\n",
    "PyTorch can be used as low level interface, but is much more user-friendly than tensorflow, but it also has a higher level interface. Pytorch is more popular in the research community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzUDYHi8D-Yd"
   },
   "source": [
    "## Main features that any deep learning library should provide\n",
    "\n",
    "No matter what library or language you use, the main features provided by a deep learning library are \n",
    "1. Use the GPU to speed up computation \n",
    "2. Ability to do automatic differentiation\n",
    "3. Useful library functions for common architectures and optimization algorithms\n",
    "\n",
    "### PyTorch\n",
    "We will look at all of the above in pytorch.\n",
    "The best way to think about pytorch is that its numpy + GPU + autograd.\n",
    "\n",
    "You can install it with\n",
    "\n",
    "```conda install pytorch```.\n",
    "\n",
    "Alternatively (and recommended), run this notebook in Google Colab-- it provides an environment with all of the PyTorch dependencies plus a GPU free of charge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fCdvNHW0D-Ye"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpWzZewHD-Yi"
   },
   "source": [
    "The equivalent object to numpy arrays in pytorch are called tensors, but they are just multidimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "t78yenP1D-Yj",
    "outputId": "c768f94e-c322-49c5-eda4-23de0ca19650"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "Efg1UeizD-Ym",
    "outputId": "3163292d-bbe0-4874-c516-9f7f983b349d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "1BlufhDpD-Yp",
    "outputId": "25d62fc7-0a07-4145-a96f-f727fe066f2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((5,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "acgFdW_4D-Yr",
    "outputId": "20c4e9e3-6483-46ec-aa41-00816d6476be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 7., 7., 7., 7.],\n",
       "        [7., 7., 7., 7., 7.],\n",
       "        [7., 7., 7., 7., 7.],\n",
       "        [7., 7., 7., 7., 7.],\n",
       "        [7., 7., 7., 7., 7.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "NwCz7O1wD-Yu",
    "outputId": "106791ec-f595-4bc7-8cde-8c70ca73f71e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7830,  0.9593, -0.2359,  0.4936,  0.0778],\n",
       "        [ 1.0929, -1.0337,  1.0417, -1.7634, -1.4706],\n",
       "        [ 1.2544,  0.2573, -2.4773,  1.8643, -0.5207],\n",
       "        [-1.3669, -2.0585, -0.0264, -0.0815,  0.9751],\n",
       "        [ 1.9430,  0.4384,  0.6319, -0.0972, -0.1088]])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "4fHiY5VKD-Yw",
    "outputId": "a1ae41f6-732e-48e7-9ee3-20757843a105"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1033, 0.1029, 0.6337, 0.1929, 0.9842, 0.8687, 0.9632, 0.3511, 0.2352,\n",
       "        0.1184, 0.7772, 0.8484, 0.2764, 0.7023, 0.2222, 0.9153, 0.1310, 0.0264,\n",
       "        0.7618, 0.5968, 0.7481, 0.8909, 0.6718, 0.6993, 0.6627])"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(25)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "0_QKyI7hD-Yz",
    "outputId": "e81700fa-6407-4cec-c5ff-8e84458daa2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1033, 0.1029, 0.6337, 0.1929, 0.9842],\n",
       "        [0.8687, 0.9632, 0.3511, 0.2352, 0.1184],\n",
       "        [0.7772, 0.8484, 0.2764, 0.7023, 0.2222],\n",
       "        [0.9153, 0.1310, 0.0264, 0.7618, 0.5968],\n",
       "        [0.7481, 0.8909, 0.6718, 0.6993, 0.6627]])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.reshape(-1,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WLKjs14-D-Y3",
    "outputId": "91ebfd91-f422-476d-f714-ba3b47144dda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "Kn9fwJoSD-Y5",
    "outputId": "fe380bb2-24f1-4951-eb0d-944c998ea886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.arange(10))\n",
    "print(torch.eye(5))\n",
    "print(torch.linspace(0,1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cix7EXwSD-Y7"
   },
   "source": [
    "Some functions are a bit different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "9BukQIL5D-Y8",
    "outputId": "09cb526f-0a4e-4456-89aa-8913e3f0183c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3641],\n",
       "        [2.4643],\n",
       "        [2.3872],\n",
       "        [2.5754],\n",
       "        [3.6095]])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(5,5)\n",
    "#or A = torch.rand((5,5))\n",
    "x = torch.ones(5,1)\n",
    "#x = torch.rand((5,1))\n",
    "A@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "k6YHvvy4D-Y-",
    "outputId": "5faf525c-3bc7-4e26-b96c-5aac96cc5e4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.95544384],\n",
       "       [1.89199807],\n",
       "       [2.52855408],\n",
       "       [1.68813529],\n",
       "       [1.83368933]])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.rand(5,5)\n",
    "x = np.ones((5,1))\n",
    "A@x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpEwcH-JD-ZA"
   },
   "source": [
    "You can convert tensors to a numpy array that shares its memory with the pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "MquNPK71D-ZC",
    "outputId": "fb4070c4-eadc-40e0-c0e8-ae1a8092d571"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(5,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "aOeMqFrOD-ZE",
    "outputId": "496640f5-39a1-49c4-d04c-2574e44fa842"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn = x.numpy()\n",
    "xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "bZlG0x9xD-ZH",
    "outputId": "8d6facdc-f0c0-4cde-8125-0ca2d63527fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  1., 10.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn[4,2]=10\n",
    "xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "sN6qJIsID-ZJ",
    "outputId": "a69dee9b-08fd-47aa-b847-50e5470c7b8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1., 10.,  1.,  1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDnSshCXD-ZL"
   },
   "source": [
    "### Using the GPU\n",
    "\n",
    "The GPU (Graphical Processing Unit) is a separate processing unit that is specialized to handle bulk computations required for rendering high quality graphics. It mainly consists of a large number of processor cores that are individually very slow, but because of their sheer number (around 2000) they can churn through computations very quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pmJ0hjO5D-ZM",
    "outputId": "6e4d5d0b-b3d5-450d-fc54-dcce1a77cdbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0kadMeJD-ZN"
   },
   "source": [
    "Installing the GPU drivers and the CUDA toolkit can be quite messy, so if you just want to experiment with GPUs and deep learning libraries, you can use [Google colaboratory](https://colab.research.google.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fCtE0kLaD-ZO"
   },
   "outputs": [],
   "source": [
    "gpu = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ESIE5J08D-ZS"
   },
   "outputs": [],
   "source": [
    "A = torch.rand(100,100)\n",
    "B = torch.rand(100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "t6VNz5SzD-ZU",
    "outputId": "53f8c0aa-0f08-4d1e-9b07-1b2bbaf7ce84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27.1041, 25.2938, 26.8609,  ..., 25.0024, 23.8091, 24.1602],\n",
       "        [24.5708, 23.0154, 24.2739,  ..., 25.5133, 21.8137, 20.8682],\n",
       "        [22.9653, 22.5256, 22.1308,  ..., 22.3759, 20.5783, 20.5542],\n",
       "        ...,\n",
       "        [27.7837, 24.3346, 27.2057,  ..., 25.6568, 23.2054, 23.6772],\n",
       "        [26.3410, 24.2153, 26.9384,  ..., 24.6268, 23.2034, 23.4321],\n",
       "        [29.0729, 25.9696, 25.7757,  ..., 24.6073, 24.7581, 25.5841]])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vXjtNNqtD-ZW"
   },
   "outputs": [],
   "source": [
    "A_gpu = A.to(gpu)\n",
    "B_gpu = B.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "krIHa3ErD-ZY",
    "outputId": "fe255051-eb71-4460-a241-44b4f9248d4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27.1041, 25.2938, 26.8609,  ..., 25.0024, 23.8091, 24.1602],\n",
       "        [24.5708, 23.0154, 24.2739,  ..., 25.5133, 21.8137, 20.8682],\n",
       "        [22.9653, 22.5256, 22.1308,  ..., 22.3759, 20.5783, 20.5542],\n",
       "        ...,\n",
       "        [27.7837, 24.3346, 27.2057,  ..., 25.6568, 23.2054, 23.6772],\n",
       "        [26.3410, 24.2153, 26.9384,  ..., 24.6268, 23.2034, 23.4321],\n",
       "        [29.0729, 25.9696, 25.7757,  ..., 24.6073, 24.7581, 25.5841]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_gpu@B_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "sox7ng2OD-ZZ"
   },
   "outputs": [],
   "source": [
    "#A@B_gpu #this won't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "j5oi8M-GD-Zc",
    "outputId": "1bde3a0f-2ab0-41ba-d4e9-0bce8ca503fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27.1041, 25.2938, 26.8609,  ..., 25.0024, 23.8091, 24.1602],\n",
       "        [24.5708, 23.0154, 24.2739,  ..., 25.5133, 21.8137, 20.8682],\n",
       "        [22.9653, 22.5256, 22.1308,  ..., 22.3759, 20.5783, 20.5542],\n",
       "        ...,\n",
       "        [27.7837, 24.3346, 27.2057,  ..., 25.6568, 23.2054, 23.6772],\n",
       "        [26.3410, 24.2153, 26.9384,  ..., 24.6268, 23.2034, 23.4321],\n",
       "        [29.0729, 25.9696, 25.7757,  ..., 24.6073, 24.7581, 25.5841]])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_gpu = A_gpu@B_gpu\n",
    "C = C_gpu.to(cpu)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JDTirUfD-Zf"
   },
   "source": [
    "### GPU - CPU memory transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jc4PxyqTD-Zf"
   },
   "outputs": [],
   "source": [
    "big_mat = torch.rand(20000,20000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OE0StFx6D-Zh"
   },
   "outputs": [],
   "source": [
    "big_mat_gpu = big_mat.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "pEI_-PmOD-Zj"
   },
   "outputs": [],
   "source": [
    "big_mat= big_mat_gpu.to(cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mx6a7G8UD-Zl"
   },
   "outputs": [],
   "source": [
    "del big_mat_gpu\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "HUt6M95HD-Zn"
   },
   "outputs": [],
   "source": [
    "del big_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vICVTE1wD-Zq"
   },
   "source": [
    "## Speedup from GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4raRnuw1D-Zr",
    "outputId": "f3af733a-9189-4d53-9ff9-d81544812b64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3.48 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "A = torch.rand(3000,3000)\n",
    "B = torch.rand(3000,3000)\n",
    "C = torch.zeros(3000,3000)\n",
    "C.copy_(B)\n",
    "for i in range(5):\n",
    "    C=torch.mm(A,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Ch47eB6OD-Zt",
    "outputId": "ee52fd9c-d381-41aa-8076-8f5ff7092a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 66.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "A = torch.rand(3000,3000, device = gpu)\n",
    "B = torch.rand(3000,3000, device = gpu)\n",
    "C = torch.zeros(3000,3000, device = gpu)\n",
    "C.copy_(B)\n",
    "for i in range(5):\n",
    "    C=torch.mm(A,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDNQLaL6D-Zu"
   },
   "source": [
    "## Automatic Differentiation\n",
    "\n",
    "PyTorch uses dynamic computation graphs to compute the gradients of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "1r6mfgjHD-Zv"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([2.0])\n",
    "m = torch.tensor([5.0], requires_grad = True)\n",
    "c = torch.tensor([2.0], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "eezGUNqXD-Zy",
    "outputId": "bf91b5e3-8b34-44fd-dde7-4bdc214c9b30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = m*x + c\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_Y_WzasD-Z0"
   },
   "source": [
    "Define an error for your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "3r7oYMHFD-Z0",
    "outputId": "798f3117-84e8-485e-a477-90b8db58f71d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.norm( y - 13)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7OuhWukrD-Z3"
   },
   "outputs": [],
   "source": [
    "m.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMhtVXAhD-Z5"
   },
   "source": [
    "Calling `x.backward()` on any tensor forces pytorch to compute all the gradients of the tensors used to compute `x` which had the `requires_grad` flag set to `True`. The computed gradient will be stored in the `.grad` property of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "5PIU90uoD-Z5"
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vYbns6g4D-Z7",
    "outputId": "d033f617-e366-4f6a-adc8-66b8bb3a18d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.])"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0MYesARFD-Z9",
    "outputId": "f771f6e0-059f-4567-ca92-9e8c3a29043d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "XDhPOJHRD-aA"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    m -= 0.01 * m.grad\n",
    "    c -= 0.3 * c.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6TlUBDHaD-aC",
    "outputId": "a8d6c7f7-cad8-4901-cbd3-df842aa8bbc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.0200], requires_grad=True), tensor([2.3000], requires_grad=True))"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Lj85MTj2D-aF",
    "outputId": "7ea7fe2f-960e-493b-8968-cf2a9e2c96d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.]), tensor([-1.]))"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.grad, c.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "J3UbDFA7D-aJ",
    "outputId": "d0a45bf2-7ead-4623-f42f-4dc0001dcf44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.]), tensor([0.]))"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.grad.zero_()\n",
    "c.grad.zero_()\n",
    "\n",
    "m.grad, c.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "PNgA5bqxD-aL"
   },
   "outputs": [],
   "source": [
    "y = m*x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LhEnrtmQD-aN",
    "outputId": "1567eaf0-e3cb-4d58-ae3c-312e864044fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12.3400], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "QJYE5aRpD-aO",
    "outputId": "6e76a585-0553-49b5-c406-d02c8c2573fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6600, grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.norm( y - 13)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "BBLYqopxD-aQ",
    "outputId": "c52f7426-b31b-4453-ac6f-485f321f620d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.]), tensor([-1.]))"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "m.grad, c.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNbj9oDlD-aS"
   },
   "source": [
    "### Making it more compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "xlQ60VuqD-aS"
   },
   "outputs": [],
   "source": [
    "def model_fn(x,m,c):\n",
    "    return m*x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "9zZHeiwJD-aV"
   },
   "outputs": [],
   "source": [
    "def loss_fn(y,yt):\n",
    "    return torch.norm(y-yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "q7drmZAzD-aX"
   },
   "outputs": [],
   "source": [
    "m = torch.tensor([5.0], requires_grad = True)\n",
    "c = torch.tensor([2.0], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ZSogMXf-D-aY"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([2.0])\n",
    "yt = torch.tensor([13.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "77BNsdU-D-aa",
    "outputId": "4fcf3780-0571-464b-8c4b-3774534bbe46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " m = tensor([5.1000], requires_grad=True)\n",
      " c = tensor([2.0500], requires_grad=True)\n",
      " y = tensor([12.], grad_fn=<AddBackward0>)\n",
      " loss = 1.0\n"
     ]
    }
   ],
   "source": [
    "y = model_fn(x,m,c)\n",
    "loss = loss_fn(y,yt)\n",
    "loss.backward()\n",
    "with torch.no_grad():\n",
    "    m -= 0.05 * m.grad\n",
    "    c -= 0.05 * c.grad\n",
    "m.grad.zero_()\n",
    "c.grad.zero_()\n",
    "\n",
    "print( f\" m = {m}\\n c = {c}\\n y = {y}\\n loss = {loss}\")\n",
    "#note that 'loss' indicates the loss for the previous m,c values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kRdaQe6D-ab"
   },
   "source": [
    "### Slightly more complicated problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Alq94bPxD-ac"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "0HdYDtWDD-ae"
   },
   "outputs": [],
   "source": [
    "def model_fn(x,m,c):\n",
    "    return m@x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "v6Cvos0BD-af"
   },
   "outputs": [],
   "source": [
    "def loss_fn(y,yt):\n",
    "    return torch.norm(y-yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "8vCjbW7HD-ah"
   },
   "outputs": [],
   "source": [
    "m = torch.rand((5,5), requires_grad = True)\n",
    "c = torch.ones((5,1), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "BsITRCClD-ai"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(5,100)\n",
    "yt = torch.randn(1,100)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NFs5CphAD-al",
    "outputId": "a53c7ef1-4bb6-468f-b2ce-952467e57071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 42.38534927368164\n",
      "loss = 38.17620849609375\n",
      "loss = 34.29269790649414\n",
      "loss = 30.80988311767578\n",
      "loss = 27.806318283081055\n",
      "loss = 25.347286224365234\n",
      "loss = 23.459623336791992\n",
      "loss = 22.111276626586914\n",
      "loss = 21.21372413635254\n",
      "loss = 20.65054702758789\n",
      "loss = 20.311750411987305\n",
      "loss = 20.113027572631836\n",
      "loss = 19.997844696044922\n",
      "loss = 19.931276321411133\n",
      "loss = 19.892711639404297\n",
      "loss = 19.87023162841797\n",
      "loss = 19.857017517089844\n",
      "loss = 19.84918212890625\n",
      "loss = 19.844486236572266\n",
      "loss = 19.84164810180664\n",
      "loss = 19.839906692504883\n",
      "loss = 19.83884048461914\n",
      "loss = 19.838171005249023\n",
      "loss = 19.837749481201172\n",
      "loss = 19.837478637695312\n",
      "loss = 19.837305068969727\n",
      "loss = 19.837194442749023\n",
      "loss = 19.837121963500977\n",
      "loss = 19.83708381652832\n",
      "loss = 19.837047576904297\n",
      "loss = 19.8370304107666\n",
      "loss = 19.837003707885742\n",
      "loss = 19.836997985839844\n",
      "loss = 19.836997985839844\n",
      "loss = 19.836990356445312\n",
      "loss = 19.836994171142578\n",
      "loss = 19.83698844909668\n",
      "loss = 19.836978912353516\n",
      "loss = 19.83698081970215\n",
      "loss = 19.836984634399414\n",
      "loss = 19.836984634399414\n",
      "loss = 19.836986541748047\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.836984634399414\n",
      "loss = 19.836978912353516\n",
      "loss = 19.836978912353516\n",
      "loss = 19.83698844909668\n",
      "loss = 19.83698272705078\n",
      "loss = 19.836978912353516\n",
      "loss = 19.83698081970215\n",
      "loss = 19.836977005004883\n",
      "loss = 19.83698272705078\n",
      "loss = 19.836986541748047\n",
      "loss = 19.83698844909668\n",
      "loss = 19.83698844909668\n",
      "loss = 19.836992263793945\n",
      "loss = 19.836986541748047\n",
      "loss = 19.836984634399414\n",
      "loss = 19.836984634399414\n",
      "loss = 19.836984634399414\n",
      "loss = 19.836984634399414\n",
      "loss = 19.836986541748047\n",
      "loss = 19.836986541748047\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.836978912353516\n",
      "loss = 19.83698081970215\n",
      "loss = 19.836978912353516\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698272705078\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n",
      "loss = 19.83698081970215\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "  y = model_fn(x,m,c)\n",
    "  loss = loss_fn(y,yt)\n",
    "  loss.backward()\n",
    "  with torch.no_grad():\n",
    "      m -= 0.05 * m.grad\n",
    "      c -= 0.05 * c.grad\n",
    "  m.grad.zero_()\n",
    "  c.grad.zero_()\n",
    "\n",
    "  losses+=[loss.item()]\n",
    "  print( f\"loss = {loss}\")\n",
    "  plt.plot(losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5t7iYj2eD-an"
   },
   "source": [
    "## Using Library functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "6xg-kywmD-an"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(5, 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "4OocRUb9D-ap",
    "outputId": "fa798f2e-0e91-4341-8992-28fb32e5469c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2015, -0.0019,  0.1120,  0.2395,  0.3313],\n",
       "         [-0.3845,  0.0647,  0.4271, -0.3099, -0.3790],\n",
       "         [ 0.2565, -0.2288,  0.0125,  0.1229,  0.3511],\n",
       "         [ 0.4114, -0.2861, -0.2163, -0.3494, -0.1167],\n",
       "         [ 0.0591, -0.0966,  0.3480, -0.4339,  0.2837]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2166, -0.3842,  0.3608, -0.2220, -0.0256], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.2141, -0.3050,  0.3272, -0.2630,  0.1940],\n",
       "         [ 0.1967, -0.1314,  0.2131,  0.2222, -0.4365],\n",
       "         [ 0.1327,  0.3509, -0.2620, -0.1779,  0.4354],\n",
       "         [ 0.3408, -0.3275, -0.3850,  0.3163,  0.1366],\n",
       "         [ 0.3936, -0.3701,  0.2420, -0.3317, -0.3789]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3465, -0.1438, -0.1364,  0.0673, -0.3204], requires_grad=True)]"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "DgBOzYv5D-aq"
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "_bdGByKKD-as"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(100,5)\n",
    "yt = torch.randn(100,1)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KupJGFEFD-at"
   },
   "source": [
    "Using the optim package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "0Ac8_-reD-au"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xtdxXUcRD-az",
    "outputId": "6f89039b-f682-4964-bec4-37a44e49a074"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 361.1955261230469\n",
      "loss = 361.193115234375\n",
      "loss = 361.34375\n",
      "loss = 361.29290771484375\n",
      "loss = 361.2300109863281\n",
      "loss = 361.0579528808594\n",
      "loss = 360.98248291015625\n",
      "loss = 361.22344970703125\n",
      "loss = 361.0437927246094\n",
      "loss = 360.92767333984375\n",
      "loss = 360.9052429199219\n",
      "loss = 361.1134033203125\n",
      "loss = 360.99822998046875\n",
      "loss = 360.8470153808594\n",
      "loss = 361.00787353515625\n",
      "loss = 361.0845947265625\n",
      "loss = 360.9836120605469\n",
      "loss = 360.92852783203125\n",
      "loss = 360.7809143066406\n",
      "loss = 360.8907165527344\n",
      "loss = 360.9651794433594\n",
      "loss = 361.0726318359375\n",
      "loss = 360.9137878417969\n",
      "loss = 360.9417419433594\n",
      "loss = 361.02044677734375\n",
      "loss = 361.0154113769531\n",
      "loss = 361.036376953125\n",
      "loss = 361.0166015625\n",
      "loss = 360.92877197265625\n",
      "loss = 360.7730407714844\n",
      "loss = 360.94561767578125\n",
      "loss = 360.77728271484375\n",
      "loss = 360.8296813964844\n",
      "loss = 360.8792419433594\n",
      "loss = 360.99737548828125\n",
      "loss = 360.9036865234375\n",
      "loss = 360.7848815917969\n",
      "loss = 360.709228515625\n",
      "loss = 360.7812194824219\n",
      "loss = 360.8575134277344\n",
      "loss = 360.9795837402344\n",
      "loss = 360.78515625\n",
      "loss = 360.79449462890625\n",
      "loss = 360.9382019042969\n",
      "loss = 360.8033447265625\n",
      "loss = 360.8541564941406\n",
      "loss = 360.8421936035156\n",
      "loss = 360.72503662109375\n",
      "loss = 360.8711853027344\n",
      "loss = 360.8279724121094\n",
      "loss = 360.896240234375\n",
      "loss = 360.82952880859375\n",
      "loss = 360.86212158203125\n",
      "loss = 360.9004211425781\n",
      "loss = 360.8726806640625\n",
      "loss = 360.9114074707031\n",
      "loss = 360.880615234375\n",
      "loss = 360.842529296875\n",
      "loss = 361.0220031738281\n",
      "loss = 360.9843444824219\n",
      "loss = 361.1358947753906\n",
      "loss = 361.0903625488281\n",
      "loss = 361.05072021484375\n",
      "loss = 361.1496887207031\n",
      "loss = 361.0906677246094\n",
      "loss = 360.9578857421875\n",
      "loss = 360.90728759765625\n",
      "loss = 361.0278015136719\n",
      "loss = 360.93853759765625\n",
      "loss = 360.86383056640625\n",
      "loss = 361.1447448730469\n",
      "loss = 360.9389343261719\n",
      "loss = 361.04132080078125\n",
      "loss = 360.8328857421875\n",
      "loss = 360.96978759765625\n",
      "loss = 361.0873107910156\n",
      "loss = 361.05303955078125\n",
      "loss = 360.80645751953125\n",
      "loss = 361.03814697265625\n",
      "loss = 360.9173583984375\n",
      "loss = 360.78656005859375\n",
      "loss = 360.85791015625\n",
      "loss = 360.8945617675781\n",
      "loss = 360.93853759765625\n",
      "loss = 360.9329833984375\n",
      "loss = 360.6997375488281\n",
      "loss = 360.8080139160156\n",
      "loss = 360.8123779296875\n",
      "loss = 360.7650146484375\n",
      "loss = 360.9565734863281\n",
      "loss = 360.9341735839844\n",
      "loss = 360.92999267578125\n",
      "loss = 360.8782653808594\n",
      "loss = 360.899658203125\n",
      "loss = 360.80108642578125\n",
      "loss = 360.790771484375\n",
      "loss = 360.8432312011719\n",
      "loss = 360.7664794921875\n",
      "loss = 360.95147705078125\n",
      "loss = 360.8257751464844\n",
      "loss = 360.804443359375\n",
      "loss = 360.962646484375\n",
      "loss = 360.85736083984375\n",
      "loss = 360.8453369140625\n",
      "loss = 361.0284729003906\n",
      "loss = 360.8887023925781\n",
      "loss = 360.8479919433594\n",
      "loss = 360.7814636230469\n",
      "loss = 360.7834777832031\n",
      "loss = 360.7204284667969\n",
      "loss = 360.9100341796875\n",
      "loss = 360.8528747558594\n",
      "loss = 360.8250427246094\n",
      "loss = 360.8099365234375\n",
      "loss = 360.7743225097656\n",
      "loss = 360.77880859375\n",
      "loss = 360.82843017578125\n",
      "loss = 360.8211364746094\n",
      "loss = 360.6737060546875\n",
      "loss = 360.8161926269531\n",
      "loss = 360.84307861328125\n",
      "loss = 360.7738952636719\n",
      "loss = 360.8343811035156\n",
      "loss = 360.92730712890625\n",
      "loss = 360.9689636230469\n",
      "loss = 360.95794677734375\n",
      "loss = 360.8154296875\n",
      "loss = 360.98846435546875\n",
      "loss = 361.0973205566406\n",
      "loss = 360.9556884765625\n",
      "loss = 361.0538330078125\n",
      "loss = 360.98236083984375\n",
      "loss = 360.9781799316406\n",
      "loss = 360.9231872558594\n",
      "loss = 360.7816467285156\n",
      "loss = 361.11920166015625\n",
      "loss = 361.07684326171875\n",
      "loss = 360.9098205566406\n",
      "loss = 360.9674987792969\n",
      "loss = 361.00823974609375\n",
      "loss = 361.09112548828125\n",
      "loss = 360.8572998046875\n",
      "loss = 360.8345947265625\n",
      "loss = 360.89569091796875\n",
      "loss = 360.83831787109375\n",
      "loss = 360.9350891113281\n",
      "loss = 360.90277099609375\n",
      "loss = 360.91796875\n",
      "loss = 360.95574951171875\n",
      "loss = 360.9418029785156\n",
      "loss = 360.97186279296875\n",
      "loss = 360.8426208496094\n",
      "loss = 360.79156494140625\n",
      "loss = 361.02349853515625\n",
      "loss = 360.9082336425781\n",
      "loss = 361.07672119140625\n",
      "loss = 360.8603820800781\n",
      "loss = 361.0169982910156\n",
      "loss = 361.0478820800781\n",
      "loss = 360.9106750488281\n",
      "loss = 360.7880859375\n",
      "loss = 361.0781555175781\n",
      "loss = 360.7860412597656\n",
      "loss = 360.8712158203125\n",
      "loss = 360.85107421875\n",
      "loss = 360.7330627441406\n",
      "loss = 360.7982177734375\n",
      "loss = 360.957275390625\n",
      "loss = 360.9050598144531\n",
      "loss = 360.6958923339844\n",
      "loss = 360.8105773925781\n",
      "loss = 360.79547119140625\n",
      "loss = 360.82965087890625\n",
      "loss = 360.897705078125\n",
      "loss = 360.9399108886719\n",
      "loss = 360.7262878417969\n",
      "loss = 361.0197448730469\n",
      "loss = 361.0450744628906\n",
      "loss = 360.9944152832031\n",
      "loss = 361.0866394042969\n",
      "loss = 361.09466552734375\n",
      "loss = 361.0702819824219\n",
      "loss = 360.8680114746094\n",
      "loss = 360.9851379394531\n",
      "loss = 361.00341796875\n",
      "loss = 360.8086853027344\n",
      "loss = 360.92431640625\n",
      "loss = 360.8560485839844\n",
      "loss = 360.8633728027344\n",
      "loss = 361.0356140136719\n",
      "loss = 360.89599609375\n",
      "loss = 361.0055847167969\n",
      "loss = 361.0185852050781\n",
      "loss = 360.9418029785156\n",
      "loss = 360.8824462890625\n",
      "loss = 360.9222412109375\n",
      "loss = 361.1231994628906\n",
      "loss = 360.84539794921875\n",
      "loss = 361.0895080566406\n",
      "loss = 361.06109619140625\n",
      "loss = 360.9761962890625\n",
      "loss = 360.8746643066406\n",
      "loss = 360.9324951171875\n",
      "loss = 361.0154113769531\n",
      "loss = 360.97503662109375\n",
      "loss = 360.92816162109375\n",
      "loss = 360.9351501464844\n",
      "loss = 360.8114318847656\n",
      "loss = 361.0599060058594\n",
      "loss = 361.0032653808594\n",
      "loss = 360.94036865234375\n",
      "loss = 361.1163024902344\n",
      "loss = 361.1067199707031\n",
      "loss = 360.99920654296875\n",
      "loss = 361.0509033203125\n",
      "loss = 361.0158996582031\n",
      "loss = 360.9274597167969\n",
      "loss = 360.9023742675781\n",
      "loss = 361.15545654296875\n",
      "loss = 361.1524353027344\n",
      "loss = 360.9892578125\n",
      "loss = 360.90960693359375\n",
      "loss = 360.99468994140625\n",
      "loss = 361.0218200683594\n",
      "loss = 360.95404052734375\n",
      "loss = 361.0540771484375\n",
      "loss = 361.0713806152344\n",
      "loss = 361.1221008300781\n",
      "loss = 361.0791320800781\n",
      "loss = 360.8305969238281\n",
      "loss = 361.04736328125\n",
      "loss = 361.05908203125\n",
      "loss = 360.9731750488281\n",
      "loss = 360.9839172363281\n",
      "loss = 360.92718505859375\n",
      "loss = 360.95318603515625\n",
      "loss = 360.9176330566406\n",
      "loss = 360.86376953125\n",
      "loss = 361.02801513671875\n",
      "loss = 360.99102783203125\n",
      "loss = 360.9222412109375\n",
      "loss = 360.9393005371094\n",
      "loss = 360.72564697265625\n",
      "loss = 360.9800720214844\n",
      "loss = 361.08697509765625\n",
      "loss = 361.02154541015625\n",
      "loss = 360.9339599609375\n",
      "loss = 360.95086669921875\n",
      "loss = 360.8131103515625\n",
      "loss = 360.8551025390625\n",
      "loss = 360.8677673339844\n",
      "loss = 360.8790588378906\n",
      "loss = 360.9207458496094\n",
      "loss = 360.9947814941406\n",
      "loss = 360.8497619628906\n",
      "loss = 360.96722412109375\n",
      "loss = 361.0570068359375\n",
      "loss = 360.8914794921875\n",
      "loss = 360.7731018066406\n",
      "loss = 360.9265441894531\n",
      "loss = 361.00689697265625\n",
      "loss = 360.91461181640625\n",
      "loss = 360.85296630859375\n",
      "loss = 360.9786071777344\n",
      "loss = 360.8197937011719\n",
      "loss = 360.861328125\n",
      "loss = 360.91192626953125\n",
      "loss = 360.93902587890625\n",
      "loss = 360.97833251953125\n",
      "loss = 361.06488037109375\n",
      "loss = 360.869140625\n",
      "loss = 360.8768310546875\n",
      "loss = 360.9781494140625\n",
      "loss = 360.9383239746094\n",
      "loss = 361.02117919921875\n",
      "loss = 361.0783996582031\n",
      "loss = 360.8654479980469\n",
      "loss = 360.8203125\n",
      "loss = 361.07891845703125\n",
      "loss = 361.0633850097656\n",
      "loss = 360.9407958984375\n",
      "loss = 360.8705749511719\n",
      "loss = 360.94097900390625\n",
      "loss = 360.95166015625\n",
      "loss = 360.90350341796875\n",
      "loss = 360.9927673339844\n",
      "loss = 360.9474792480469\n",
      "loss = 360.8708801269531\n",
      "loss = 360.76666259765625\n",
      "loss = 361.0648193359375\n",
      "loss = 360.9278259277344\n",
      "loss = 360.95159912109375\n",
      "loss = 361.0418395996094\n",
      "loss = 361.0544738769531\n",
      "loss = 360.9557189941406\n",
      "loss = 360.88714599609375\n",
      "loss = 360.8963317871094\n",
      "loss = 360.9844055175781\n",
      "loss = 360.82244873046875\n",
      "loss = 360.97021484375\n",
      "loss = 360.990966796875\n",
      "loss = 360.91314697265625\n",
      "loss = 360.7695617675781\n",
      "loss = 360.9241943359375\n",
      "loss = 360.88238525390625\n",
      "loss = 360.8254089355469\n",
      "loss = 360.89306640625\n",
      "loss = 360.807373046875\n",
      "loss = 360.94842529296875\n",
      "loss = 361.2075500488281\n",
      "loss = 361.1253967285156\n",
      "loss = 360.90350341796875\n",
      "loss = 360.9454040527344\n",
      "loss = 360.966064453125\n",
      "loss = 361.061279296875\n",
      "loss = 360.89459228515625\n",
      "loss = 360.9974365234375\n",
      "loss = 360.96575927734375\n",
      "loss = 360.8348083496094\n",
      "loss = 361.3282165527344\n",
      "loss = 360.98046875\n",
      "loss = 360.96099853515625\n",
      "loss = 361.027587890625\n",
      "loss = 360.8177795410156\n",
      "loss = 360.77947998046875\n",
      "loss = 360.8650207519531\n",
      "loss = 360.7241516113281\n",
      "loss = 360.8352355957031\n",
      "loss = 360.79949951171875\n",
      "loss = 360.7789611816406\n",
      "loss = 360.7876892089844\n",
      "loss = 360.8355712890625\n",
      "loss = 360.9787902832031\n",
      "loss = 360.985595703125\n",
      "loss = 360.8309020996094\n",
      "loss = 360.8253479003906\n",
      "loss = 360.8380126953125\n",
      "loss = 360.7884216308594\n",
      "loss = 360.8442077636719\n",
      "loss = 360.6865234375\n",
      "loss = 360.6559753417969\n",
      "loss = 361.0126953125\n",
      "loss = 360.7228088378906\n",
      "loss = 360.94146728515625\n",
      "loss = 360.9710388183594\n",
      "loss = 361.06744384765625\n",
      "loss = 361.019775390625\n",
      "loss = 360.82415771484375\n",
      "loss = 360.8323059082031\n",
      "loss = 360.8451843261719\n",
      "loss = 360.8001403808594\n",
      "loss = 360.99871826171875\n",
      "loss = 360.86090087890625\n",
      "loss = 360.8674011230469\n",
      "loss = 360.98199462890625\n",
      "loss = 361.0290832519531\n",
      "loss = 360.8996276855469\n",
      "loss = 360.83062744140625\n",
      "loss = 360.8832702636719\n",
      "loss = 360.78076171875\n",
      "loss = 360.9854431152344\n",
      "loss = 360.89935302734375\n",
      "loss = 360.88763427734375\n",
      "loss = 360.9511413574219\n",
      "loss = 360.87188720703125\n",
      "loss = 360.8586120605469\n",
      "loss = 360.7962341308594\n",
      "loss = 360.9015197753906\n",
      "loss = 360.9873352050781\n",
      "loss = 361.0082092285156\n",
      "loss = 360.9536437988281\n",
      "loss = 360.9684143066406\n",
      "loss = 360.93634033203125\n",
      "loss = 360.8645324707031\n",
      "loss = 360.7366027832031\n",
      "loss = 360.9603576660156\n",
      "loss = 360.9044494628906\n",
      "loss = 360.8050842285156\n",
      "loss = 360.85693359375\n",
      "loss = 361.0750427246094\n",
      "loss = 360.907470703125\n",
      "loss = 360.76446533203125\n",
      "loss = 360.8358459472656\n",
      "loss = 360.9017639160156\n",
      "loss = 360.75494384765625\n",
      "loss = 360.7115173339844\n",
      "loss = 360.8087158203125\n",
      "loss = 360.7863464355469\n",
      "loss = 360.89605712890625\n",
      "loss = 361.02099609375\n",
      "loss = 360.95831298828125\n",
      "loss = 361.0845031738281\n",
      "loss = 361.1194763183594\n",
      "loss = 361.1004943847656\n",
      "loss = 360.88623046875\n",
      "loss = 361.06207275390625\n",
      "loss = 361.1400146484375\n",
      "loss = 361.0639953613281\n",
      "loss = 360.8175354003906\n",
      "loss = 360.9466857910156\n",
      "loss = 361.16278076171875\n",
      "loss = 361.0379943847656\n",
      "loss = 361.0585632324219\n",
      "loss = 360.9418029785156\n",
      "loss = 360.8863830566406\n",
      "loss = 360.9263610839844\n",
      "loss = 360.7846374511719\n",
      "loss = 360.8931579589844\n",
      "loss = 361.1355895996094\n",
      "loss = 361.20013427734375\n",
      "loss = 361.00897216796875\n",
      "loss = 360.989990234375\n",
      "loss = 361.1552734375\n",
      "loss = 361.2701416015625\n",
      "loss = 361.100341796875\n",
      "loss = 360.9319763183594\n",
      "loss = 360.93408203125\n",
      "loss = 361.08209228515625\n",
      "loss = 361.0205993652344\n",
      "loss = 360.8030700683594\n",
      "loss = 360.999267578125\n",
      "loss = 361.1251220703125\n",
      "loss = 361.0964050292969\n",
      "loss = 360.9759826660156\n",
      "loss = 360.9139709472656\n",
      "loss = 360.9171142578125\n",
      "loss = 360.9859924316406\n",
      "loss = 360.8119812011719\n",
      "loss = 360.8553161621094\n",
      "loss = 360.8879089355469\n",
      "loss = 360.9329833984375\n",
      "loss = 360.918701171875\n",
      "loss = 360.86328125\n",
      "loss = 360.9091491699219\n",
      "loss = 360.79095458984375\n",
      "loss = 360.88323974609375\n",
      "loss = 360.9588623046875\n",
      "loss = 360.855712890625\n",
      "loss = 360.9227600097656\n",
      "loss = 360.9435729980469\n",
      "loss = 360.971923828125\n",
      "loss = 360.8581237792969\n",
      "loss = 360.8360290527344\n",
      "loss = 360.74957275390625\n",
      "loss = 360.74835205078125\n",
      "loss = 360.8092956542969\n",
      "loss = 360.79656982421875\n",
      "loss = 360.84393310546875\n",
      "loss = 360.7929382324219\n",
      "loss = 360.7207336425781\n",
      "loss = 360.8375549316406\n",
      "loss = 360.7608642578125\n",
      "loss = 360.71417236328125\n",
      "loss = 360.6634826660156\n",
      "loss = 360.7435607910156\n",
      "loss = 360.8302307128906\n",
      "loss = 360.7438049316406\n",
      "loss = 360.82110595703125\n",
      "loss = 360.84747314453125\n",
      "loss = 360.9052734375\n",
      "loss = 360.8872985839844\n",
      "loss = 360.9432067871094\n",
      "loss = 361.0463562011719\n",
      "loss = 360.99456787109375\n",
      "loss = 360.9770812988281\n",
      "loss = 360.95904541015625\n",
      "loss = 360.8400573730469\n",
      "loss = 360.9575500488281\n",
      "loss = 360.6943664550781\n",
      "loss = 360.81439208984375\n",
      "loss = 360.90155029296875\n",
      "loss = 360.71270751953125\n",
      "loss = 361.1097106933594\n",
      "loss = 360.9533386230469\n",
      "loss = 360.8597412109375\n",
      "loss = 360.9715576171875\n",
      "loss = 360.913818359375\n",
      "loss = 360.99700927734375\n",
      "loss = 361.00189208984375\n",
      "loss = 360.96563720703125\n",
      "loss = 360.9530334472656\n",
      "loss = 361.1155090332031\n",
      "loss = 361.01702880859375\n",
      "loss = 360.8537292480469\n",
      "loss = 361.1003723144531\n",
      "loss = 361.1167907714844\n",
      "loss = 361.21478271484375\n",
      "loss = 361.1571960449219\n",
      "loss = 360.9653625488281\n",
      "loss = 360.76239013671875\n",
      "loss = 360.9161376953125\n",
      "loss = 360.9448547363281\n",
      "loss = 360.9705505371094\n",
      "loss = 361.0132141113281\n",
      "loss = 360.93695068359375\n",
      "loss = 360.93231201171875\n",
      "loss = 360.9276428222656\n",
      "loss = 360.9534912109375\n",
      "loss = 360.981689453125\n",
      "loss = 360.7805480957031\n",
      "loss = 360.9551696777344\n",
      "loss = 360.8982238769531\n",
      "loss = 360.7857360839844\n",
      "loss = 360.9830322265625\n",
      "loss = 360.91748046875\n",
      "loss = 360.8032531738281\n",
      "loss = 360.8783264160156\n",
      "loss = 360.9069519042969\n",
      "loss = 360.90386962890625\n",
      "loss = 360.7509460449219\n",
      "loss = 360.8309326171875\n",
      "loss = 360.72784423828125\n",
      "loss = 360.7850341796875\n",
      "loss = 360.8780212402344\n",
      "loss = 360.8332214355469\n",
      "loss = 360.7919006347656\n",
      "loss = 360.8268737792969\n",
      "loss = 360.78466796875\n",
      "loss = 360.8609924316406\n",
      "loss = 361.01025390625\n",
      "loss = 360.9675598144531\n",
      "loss = 360.9444274902344\n",
      "loss = 360.96453857421875\n",
      "loss = 360.8766174316406\n",
      "loss = 360.8091125488281\n",
      "loss = 360.8136291503906\n",
      "loss = 361.00537109375\n",
      "loss = 360.75164794921875\n",
      "loss = 360.7819519042969\n",
      "loss = 360.9060363769531\n",
      "loss = 360.7903137207031\n",
      "loss = 360.8970947265625\n",
      "loss = 360.92803955078125\n",
      "loss = 360.9407043457031\n",
      "loss = 360.8889465332031\n",
      "loss = 360.77154541015625\n",
      "loss = 360.881103515625\n",
      "loss = 360.86444091796875\n",
      "loss = 360.802734375\n",
      "loss = 360.8248291015625\n",
      "loss = 360.72247314453125\n",
      "loss = 360.9719543457031\n",
      "loss = 360.9836120605469\n",
      "loss = 360.903564453125\n",
      "loss = 360.94073486328125\n",
      "loss = 361.2076110839844\n",
      "loss = 360.91552734375\n",
      "loss = 360.8486022949219\n",
      "loss = 360.7634582519531\n",
      "loss = 360.7520446777344\n",
      "loss = 360.8573303222656\n",
      "loss = 360.7247619628906\n",
      "loss = 360.79608154296875\n",
      "loss = 360.9584655761719\n",
      "loss = 360.9736022949219\n",
      "loss = 360.8254089355469\n",
      "loss = 360.81103515625\n",
      "loss = 360.93829345703125\n",
      "loss = 360.815673828125\n",
      "loss = 360.8077392578125\n",
      "loss = 360.96405029296875\n",
      "loss = 360.750732421875\n",
      "loss = 360.8085632324219\n",
      "loss = 360.92303466796875\n",
      "loss = 360.7846374511719\n",
      "loss = 360.8368225097656\n",
      "loss = 360.78619384765625\n",
      "loss = 360.8011474609375\n",
      "loss = 360.8272705078125\n",
      "loss = 360.7681884765625\n",
      "loss = 360.7585754394531\n",
      "loss = 360.77691650390625\n",
      "loss = 360.79437255859375\n",
      "loss = 360.86181640625\n",
      "loss = 360.8734436035156\n",
      "loss = 360.9012451171875\n",
      "loss = 360.87103271484375\n",
      "loss = 360.768310546875\n",
      "loss = 360.82611083984375\n",
      "loss = 360.87432861328125\n",
      "loss = 360.95098876953125\n",
      "loss = 360.8969421386719\n",
      "loss = 360.87255859375\n",
      "loss = 360.9031982421875\n",
      "loss = 360.9203186035156\n",
      "loss = 361.058837890625\n",
      "loss = 360.85650634765625\n",
      "loss = 360.93231201171875\n",
      "loss = 360.9862365722656\n",
      "loss = 360.7888488769531\n",
      "loss = 360.8873291015625\n",
      "loss = 360.8027038574219\n",
      "loss = 361.02239990234375\n",
      "loss = 360.9505310058594\n",
      "loss = 360.9344482421875\n",
      "loss = 360.95245361328125\n",
      "loss = 360.8157653808594\n",
      "loss = 360.9936828613281\n",
      "loss = 361.0724182128906\n",
      "loss = 360.93048095703125\n",
      "loss = 361.0035095214844\n",
      "loss = 360.87042236328125\n",
      "loss = 360.9117431640625\n",
      "loss = 361.0666198730469\n",
      "loss = 360.9418029785156\n",
      "loss = 360.8458557128906\n",
      "loss = 360.95440673828125\n",
      "loss = 361.07476806640625\n",
      "loss = 360.9954833984375\n",
      "loss = 360.9282531738281\n",
      "loss = 360.93408203125\n",
      "loss = 360.9277038574219\n",
      "loss = 360.9488525390625\n",
      "loss = 360.9015197753906\n",
      "loss = 360.9461669921875\n",
      "loss = 360.9907531738281\n",
      "loss = 360.79193115234375\n",
      "loss = 360.8734130859375\n",
      "loss = 360.9040222167969\n",
      "loss = 360.89593505859375\n",
      "loss = 360.8249816894531\n",
      "loss = 360.8534240722656\n",
      "loss = 360.8591613769531\n",
      "loss = 360.95184326171875\n",
      "loss = 360.798828125\n",
      "loss = 360.82928466796875\n",
      "loss = 360.90252685546875\n",
      "loss = 361.0926818847656\n",
      "loss = 360.9911804199219\n",
      "loss = 360.9867858886719\n",
      "loss = 360.92791748046875\n",
      "loss = 360.81085205078125\n",
      "loss = 360.8092346191406\n",
      "loss = 360.944091796875\n",
      "loss = 361.0533752441406\n",
      "loss = 360.9993591308594\n",
      "loss = 360.8320617675781\n",
      "loss = 360.8966369628906\n",
      "loss = 360.8768005371094\n",
      "loss = 360.97625732421875\n",
      "loss = 360.9579162597656\n",
      "loss = 361.0897216796875\n",
      "loss = 360.9494323730469\n",
      "loss = 360.86505126953125\n",
      "loss = 361.0394592285156\n",
      "loss = 360.81640625\n",
      "loss = 360.9704895019531\n",
      "loss = 361.06243896484375\n",
      "loss = 360.9183654785156\n",
      "loss = 361.0491027832031\n",
      "loss = 360.86431884765625\n",
      "loss = 360.97943115234375\n",
      "loss = 361.0592956542969\n",
      "loss = 360.8450622558594\n",
      "loss = 360.80572509765625\n",
      "loss = 360.99627685546875\n",
      "loss = 360.8603515625\n",
      "loss = 360.6801452636719\n",
      "loss = 360.9715576171875\n",
      "loss = 361.02435302734375\n",
      "loss = 360.92852783203125\n",
      "loss = 360.95196533203125\n",
      "loss = 360.9065246582031\n",
      "loss = 360.8931884765625\n",
      "loss = 360.8517150878906\n",
      "loss = 360.7427062988281\n",
      "loss = 360.76226806640625\n",
      "loss = 360.847412109375\n",
      "loss = 360.7939147949219\n",
      "loss = 360.8409729003906\n",
      "loss = 360.7829284667969\n",
      "loss = 360.70123291015625\n",
      "loss = 360.74298095703125\n",
      "loss = 360.900634765625\n",
      "loss = 360.8054504394531\n",
      "loss = 360.7967224121094\n",
      "loss = 360.9062194824219\n",
      "loss = 360.9389343261719\n",
      "loss = 360.8678894042969\n",
      "loss = 360.8376159667969\n",
      "loss = 361.0014343261719\n",
      "loss = 360.9594421386719\n",
      "loss = 360.856201171875\n",
      "loss = 360.7870178222656\n",
      "loss = 360.8714904785156\n",
      "loss = 360.9959411621094\n",
      "loss = 360.8792419433594\n",
      "loss = 360.940185546875\n",
      "loss = 361.0174255371094\n",
      "loss = 360.9574279785156\n",
      "loss = 360.89654541015625\n",
      "loss = 360.7216796875\n",
      "loss = 360.7724609375\n",
      "loss = 360.8521728515625\n",
      "loss = 360.7410583496094\n",
      "loss = 360.87701416015625\n",
      "loss = 360.93792724609375\n",
      "loss = 360.929443359375\n",
      "loss = 360.7759704589844\n",
      "loss = 360.85205078125\n",
      "loss = 360.6873474121094\n",
      "loss = 360.90673828125\n",
      "loss = 360.9527587890625\n",
      "loss = 360.7702331542969\n",
      "loss = 360.9263916015625\n",
      "loss = 360.8360900878906\n",
      "loss = 360.9002990722656\n",
      "loss = 361.0654296875\n",
      "loss = 360.9252624511719\n",
      "loss = 360.74267578125\n",
      "loss = 360.773681640625\n",
      "loss = 360.74639892578125\n",
      "loss = 360.882080078125\n",
      "loss = 360.76654052734375\n",
      "loss = 360.6540222167969\n",
      "loss = 361.0628967285156\n",
      "loss = 361.0081787109375\n",
      "loss = 360.8561706542969\n",
      "loss = 361.2520751953125\n",
      "loss = 361.1435852050781\n",
      "loss = 361.0762634277344\n",
      "loss = 361.16192626953125\n",
      "loss = 360.9501037597656\n",
      "loss = 360.9263610839844\n",
      "loss = 360.83135986328125\n",
      "loss = 360.7985534667969\n",
      "loss = 360.8894348144531\n",
      "loss = 360.8550109863281\n",
      "loss = 360.7031555175781\n",
      "loss = 360.9405517578125\n",
      "loss = 360.9250793457031\n",
      "loss = 360.88812255859375\n",
      "loss = 360.8935241699219\n",
      "loss = 360.7876892089844\n",
      "loss = 360.89044189453125\n",
      "loss = 361.0600891113281\n",
      "loss = 360.98162841796875\n",
      "loss = 360.7972106933594\n",
      "loss = 361.0887451171875\n",
      "loss = 361.05340576171875\n",
      "loss = 360.8844909667969\n",
      "loss = 360.9128112792969\n",
      "loss = 360.92840576171875\n",
      "loss = 361.0039978027344\n",
      "loss = 361.0804443359375\n",
      "loss = 360.77764892578125\n",
      "loss = 361.0039978027344\n",
      "loss = 361.0618591308594\n",
      "loss = 360.9653625488281\n",
      "loss = 361.00885009765625\n",
      "loss = 361.1019287109375\n",
      "loss = 361.0261535644531\n",
      "loss = 360.8746643066406\n",
      "loss = 360.8455505371094\n",
      "loss = 360.8030700683594\n",
      "loss = 361.0028381347656\n",
      "loss = 360.95989990234375\n",
      "loss = 360.7626037597656\n",
      "loss = 361.0236511230469\n",
      "loss = 361.0999450683594\n",
      "loss = 360.8758239746094\n",
      "loss = 361.1668395996094\n",
      "loss = 361.210693359375\n",
      "loss = 361.05767822265625\n",
      "loss = 361.06005859375\n",
      "loss = 360.9543762207031\n",
      "loss = 360.866943359375\n",
      "loss = 361.00970458984375\n",
      "loss = 360.9378967285156\n",
      "loss = 361.0440979003906\n",
      "loss = 361.14691162109375\n",
      "loss = 361.1784973144531\n",
      "loss = 361.1156311035156\n",
      "loss = 360.8171081542969\n",
      "loss = 361.1019592285156\n",
      "loss = 361.2318420410156\n",
      "loss = 361.07806396484375\n",
      "loss = 360.8816223144531\n",
      "loss = 361.0793762207031\n",
      "loss = 360.9966735839844\n",
      "loss = 360.9189453125\n",
      "loss = 361.3204345703125\n",
      "loss = 360.9059143066406\n",
      "loss = 360.9286193847656\n",
      "loss = 361.13958740234375\n",
      "loss = 361.06292724609375\n",
      "loss = 360.8920593261719\n",
      "loss = 360.821533203125\n",
      "loss = 360.9749755859375\n",
      "loss = 361.05645751953125\n",
      "loss = 361.0322570800781\n",
      "loss = 361.0705871582031\n",
      "loss = 360.9208984375\n",
      "loss = 360.98211669921875\n",
      "loss = 360.8518981933594\n",
      "loss = 360.7848205566406\n",
      "loss = 361.0078125\n",
      "loss = 360.7684631347656\n",
      "loss = 360.8299255371094\n",
      "loss = 360.9208679199219\n",
      "loss = 360.86474609375\n",
      "loss = 360.8413391113281\n",
      "loss = 360.9154968261719\n",
      "loss = 360.8684997558594\n",
      "loss = 360.9813232421875\n",
      "loss = 361.0277404785156\n",
      "loss = 360.94085693359375\n",
      "loss = 360.9147644042969\n",
      "loss = 360.8856506347656\n",
      "loss = 360.7853088378906\n",
      "loss = 360.90228271484375\n",
      "loss = 360.82958984375\n",
      "loss = 361.08197021484375\n",
      "loss = 360.9240417480469\n",
      "loss = 360.828857421875\n",
      "loss = 360.9342346191406\n",
      "loss = 361.05999755859375\n",
      "loss = 360.90484619140625\n",
      "loss = 360.91552734375\n",
      "loss = 360.95220947265625\n",
      "loss = 361.0264892578125\n",
      "loss = 361.1515808105469\n",
      "loss = 360.8870849609375\n",
      "loss = 360.8225402832031\n",
      "loss = 360.943115234375\n",
      "loss = 360.9949035644531\n",
      "loss = 360.93096923828125\n",
      "loss = 361.01763916015625\n",
      "loss = 360.9971008300781\n",
      "loss = 360.8323974609375\n",
      "loss = 360.8010559082031\n",
      "loss = 360.7580871582031\n",
      "loss = 360.916259765625\n",
      "loss = 360.80865478515625\n",
      "loss = 360.9336242675781\n",
      "loss = 360.97747802734375\n",
      "loss = 360.9301452636719\n",
      "loss = 360.97998046875\n",
      "loss = 360.9627380371094\n",
      "loss = 360.9659423828125\n",
      "loss = 361.02423095703125\n",
      "loss = 361.0448913574219\n",
      "loss = 360.97052001953125\n",
      "loss = 361.1337585449219\n",
      "loss = 361.0638122558594\n",
      "loss = 361.0795593261719\n",
      "loss = 360.9261779785156\n",
      "loss = 360.9757385253906\n",
      "loss = 361.1656799316406\n",
      "loss = 361.32135009765625\n",
      "loss = 361.33795166015625\n",
      "loss = 361.2818298339844\n",
      "loss = 361.17913818359375\n",
      "loss = 361.00506591796875\n",
      "loss = 361.04290771484375\n",
      "loss = 361.04913330078125\n",
      "loss = 361.0383605957031\n",
      "loss = 360.87811279296875\n",
      "loss = 360.8720703125\n",
      "loss = 360.9573059082031\n",
      "loss = 360.94134521484375\n",
      "loss = 360.86773681640625\n",
      "loss = 360.8231201171875\n",
      "loss = 360.71221923828125\n",
      "loss = 360.8829345703125\n",
      "loss = 360.8923645019531\n",
      "loss = 360.79437255859375\n",
      "loss = 360.8409423828125\n",
      "loss = 360.999755859375\n",
      "loss = 360.96728515625\n",
      "loss = 361.0494079589844\n",
      "loss = 361.01226806640625\n",
      "loss = 360.85125732421875\n",
      "loss = 360.847412109375\n",
      "loss = 360.8562316894531\n",
      "loss = 360.80096435546875\n",
      "loss = 360.7286376953125\n",
      "loss = 360.716064453125\n",
      "loss = 360.800537109375\n",
      "loss = 360.8406066894531\n",
      "loss = 361.0148010253906\n",
      "loss = 361.0029602050781\n",
      "loss = 360.8634033203125\n",
      "loss = 360.74761962890625\n",
      "loss = 360.7816467285156\n",
      "loss = 360.7906188964844\n",
      "loss = 360.73248291015625\n",
      "loss = 360.74481201171875\n",
      "loss = 360.9346008300781\n",
      "loss = 360.9738464355469\n",
      "loss = 360.8214111328125\n",
      "loss = 360.8858642578125\n",
      "loss = 360.8035583496094\n",
      "loss = 361.00164794921875\n",
      "loss = 360.8389587402344\n",
      "loss = 360.9508056640625\n",
      "loss = 360.9875793457031\n",
      "loss = 360.9003601074219\n",
      "loss = 360.947265625\n",
      "loss = 360.98858642578125\n",
      "loss = 361.1059265136719\n",
      "loss = 361.00189208984375\n",
      "loss = 360.9624938964844\n",
      "loss = 360.9496765136719\n",
      "loss = 361.03729248046875\n",
      "loss = 360.8477478027344\n",
      "loss = 360.85748291015625\n",
      "loss = 360.9432373046875\n",
      "loss = 360.9881591796875\n",
      "loss = 361.0863952636719\n",
      "loss = 361.0258483886719\n",
      "loss = 361.0370788574219\n",
      "loss = 361.14105224609375\n",
      "loss = 361.12896728515625\n",
      "loss = 361.2052001953125\n",
      "loss = 361.2183532714844\n",
      "loss = 360.86053466796875\n",
      "loss = 361.0171813964844\n",
      "loss = 361.2571105957031\n",
      "loss = 361.03204345703125\n",
      "loss = 360.8537292480469\n",
      "loss = 361.1061706542969\n",
      "loss = 361.1612243652344\n",
      "loss = 360.9912414550781\n",
      "loss = 361.0252380371094\n",
      "loss = 361.1233825683594\n",
      "loss = 360.86053466796875\n",
      "loss = 360.8650817871094\n",
      "loss = 361.06561279296875\n",
      "loss = 361.06060791015625\n",
      "loss = 361.0187072753906\n",
      "loss = 361.1136169433594\n",
      "loss = 361.0668029785156\n",
      "loss = 360.9283752441406\n",
      "loss = 360.9519348144531\n",
      "loss = 360.91162109375\n",
      "loss = 360.80279541015625\n",
      "loss = 360.8165588378906\n",
      "loss = 360.87103271484375\n",
      "loss = 360.7929992675781\n",
      "loss = 360.8466491699219\n",
      "loss = 361.0654602050781\n",
      "loss = 361.12213134765625\n",
      "loss = 360.96807861328125\n",
      "loss = 360.9147644042969\n",
      "loss = 360.9315185546875\n",
      "loss = 361.11395263671875\n",
      "loss = 361.0964660644531\n",
      "loss = 361.12811279296875\n",
      "loss = 361.00128173828125\n",
      "loss = 361.09967041015625\n",
      "loss = 361.25701904296875\n",
      "loss = 361.151123046875\n",
      "loss = 361.1060485839844\n",
      "loss = 361.0189514160156\n",
      "loss = 360.8484802246094\n",
      "loss = 361.0215759277344\n",
      "loss = 361.1968994140625\n",
      "loss = 361.1138916015625\n",
      "loss = 360.8956604003906\n",
      "loss = 361.10687255859375\n",
      "loss = 361.12664794921875\n",
      "loss = 361.064697265625\n",
      "loss = 361.2191467285156\n",
      "loss = 360.9731140136719\n",
      "loss = 360.93267822265625\n",
      "loss = 360.8743591308594\n",
      "loss = 360.998046875\n",
      "loss = 360.8592529296875\n",
      "loss = 360.8665771484375\n",
      "loss = 360.9410400390625\n",
      "loss = 360.8306884765625\n",
      "loss = 360.9259033203125\n",
      "loss = 360.75244140625\n",
      "loss = 360.8835754394531\n",
      "loss = 361.0990295410156\n",
      "loss = 360.90936279296875\n",
      "loss = 360.9346008300781\n",
      "loss = 360.9739074707031\n",
      "loss = 360.86029052734375\n",
      "loss = 360.97027587890625\n",
      "loss = 360.8242492675781\n",
      "loss = 360.7661437988281\n",
      "loss = 360.8711242675781\n",
      "loss = 360.75555419921875\n",
      "loss = 360.82513427734375\n",
      "loss = 360.77032470703125\n",
      "loss = 360.871337890625\n",
      "loss = 360.8871765136719\n",
      "loss = 360.8132629394531\n",
      "loss = 360.9269714355469\n",
      "loss = 360.8593444824219\n",
      "loss = 360.83349609375\n",
      "loss = 360.9953918457031\n",
      "loss = 360.9367980957031\n",
      "loss = 360.9209289550781\n",
      "loss = 360.9575500488281\n",
      "loss = 360.7529602050781\n",
      "loss = 361.0162353515625\n",
      "loss = 360.8441162109375\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAb5ElEQVR4nO3de3Bc53nf8e+ze/a+uBO8CCAFXShFN4uWYVmtHSmxM7KluJacNonaNFJdz6juKDPOuK0j1TMdT2f8h9u4TtxmnCi2E9mWY6tONFYutaVYVjquI1mgRFHUhRJIUSIogARB4r73ffvHnqUWFEgBJLCLPef3mcHg7LtnsQ/PLn588ey5mHMOEREJlkirCxARkbWncBcRCSCFu4hIACncRUQCSOEuIhJAXqsLANi0aZMbGhpqdRkiIm1l9+7dx51z/cvdtyHCfWhoiJGRkVaXISLSVszs9TPdp7aMiEgAKdxFRAJI4S4iEkAKdxGRAFK4i4gEkMJdRCSAFO4iIgHU1uG+f2KOLz26n+PzhVaXIiKyobR1uI8em+d/Pj7K1Hyx1aWIiGwobR3uUb/6SlUXHBERadTW4R4xA6Cqq0mJiCzR1uEejdTCXTN3EZGl2jrcI/Vw18xdRGSJtg73aL0to5m7iMgS7R3uasuIiCxL4S4iEkDBCHf13EVElmjrcK/vCqmZu4jIUm0d7vWZu/ZzFxFZqr3D/dTMvcWFiIhsMG0d7hGdfkBEZFltHe5qy4iILK+9w10fqIqILKutwz2imbuIyLJWFO5mdsjMnjezPWY24o993syO+GN7zOzWhvXvM7NRM9tvZh9er+I1cxcRWZ63inV/2Tl3/LSxLzvnfr9xwMyuBO4ArgIuAP7ezC5zzlXOr9S30xGqIiLLW4+2zG3Ad51zBefca8AocP06PI/aMiIiZ7DScHfAo2a228zubhj/HTPba2bfMLMef2wAONywzpg/tua0n7uIyPJWGu4fcM5dB9wC3GNmNwJfBS4BdgHjwJdW88RmdreZjZjZyOTk5Goeesqp/dw1cxcRWWJF4e6cO+J/PwY8DFzvnDvqnKs456rAn/JW6+UIsL3h4YP+2Ok/837n3LBzbri/v/+citf53EVElveO4W5mGTPrqC8DNwP7zGxbw2ofB/b5y48Ad5hZwswuAnYCP1/bsmv0gaqIyPJWsrfMFuBhq82SPeA7zrkfmtm3zGwXtX78IeDfATjnXjCzh4AXgTJwz3rsKQP6QFVE5EzeMdydcweBa5cZ/+2zPOYLwBfOr7R35vnhXtbMXURkifY+QlUHMYmILKutwz0erZVf0r6QIiJLtHW4RyJGPBqhUFa4i4g0autwB4h7EQolhbuISKO2D/eEF6FQXpedcURE2lZAwl0zdxGRRu0f7rEoRYW7iMgSbR/utQ9U1ZYREWnU9uGeiKktIyJyuvYPd+0tIyLyNgEI96jaMiIip2n7cM8mPOby5VaXISKyobR9uHelYszkSq0uQ0RkQ2n/cE8r3EVETtf+4Z6KUShXyZfUdxcRqWv7cO9MxQCY1exdROSUtg/3Lj/c1ZoREXlLYMJ9Nq9wFxGpC0y4a+YuIvIWhbuISAAFJ9wXFe4iInVtH+4dSQ+AmZyOUhURqWv7cI9FI2TiUbVlREQatH24g05BICJyukCEe6fCXURkiUCEe1cqpiNURUQaBCbcNXMXEXlLIMK9IxljvqC9ZURE6gIR7plElIWiwl1EpC4g4e6xoJm7iMgpgQj3bMKjVHG6lqqIiC8Q4Z6JRwFYLCjcRUQgIOGeTtROQaAPVUVEagIR7lk/3PWhqohITSDCPVMPd83cRUSAgIR7NlHruS+o5y4iAgQk3NNxzdxFRBoFItyz+kBVRGSJQIS7eu4iIkutKNzN7JCZPW9me8xsxB/rNbPHzOxV/3uPP25m9hUzGzWzvWZ23Xr+A6B2+gGAhaJ67iIisLqZ+y8753Y554b92/cCP3bO7QR+7N8GuAXY6X/dDXx1rYo9k3g0ghcxzdxFRHzn05a5DXjAX34AuL1h/Juu5kmg28y2ncfzvCMz0/llREQarDTcHfCome02s7v9sS3OuXF/eQLY4i8PAIcbHjvmjy1hZneb2YiZjUxOTp5D6UtlEx7z2hVSRAQAb4XrfcA5d8TMNgOPmdnLjXc655yZudU8sXPufuB+gOHh4VU9djmZRJRFHaEqIgKscObunDvifz8GPAxcDxytt1v878f81Y8A2xsePuiPrat03NOukCIivncMdzPLmFlHfRm4GdgHPALc5a92F/ADf/kR4E5/r5kbgJmG9s26yarnLiJyykraMluAh82svv53nHM/NLOngYfM7JPA68Bv+Ov/HXArMAosAp9Y86qXkUlEmZwrNOOpREQ2vHcMd+fcQeDaZcangA8tM+6Ae9akulXIJDydFVJExBeII1QBMnG1ZURE6oIT7glPZ4UUEfEFJtyziSjFSpViudrqUkREWi4w4V4/eZj2dRcRCVK4x3XaXxGRuuCE+6nT/qrvLiISoHCvnfZXM3cRkQCFe1Y9dxGRUwIT7rqOqojIWwIT7m9dR1U9dxGRwIT7qUvtaeYuIhKkcPfbMuq5i4gEJ9wTXoSorqMqIgIEKNzNjEw8qv3cRUQIULhD/TqqmrmLiAQq3DMJT/u5i4gQsHBPJzztCikiQsDCPZuI6gNVERECFu66GpOISE2gwj2r66iKiAABC/d0QrtCiohAwMI9o10hRUSAgIV7Nu5RLFcpVXQdVREJt0CF+6nrqKo1IyIhF7Bwr50Zcq5QanElIiKtFahw70zGAJjLq+8uIuEWrHBP1cJ9NqeZu4iEW6DCvcsP9xmFu4iEXKDCvd6WmVVbRkRCLljhnqrtLaO2jIiEXaDCvSOptoyICAQs3KMRoyPhMZtXuItIuAUq3KG2x8xsTj13EQm3QIa72jIiEnbBC/ek2jIiIoEL965UTHvLiEjoBS7cOxXuIiIBDPdkTAcxiUjorTjczSxqZs+a2d/4t//czF4zsz3+1y5/3MzsK2Y2amZ7zey69Sp+OV2pGPOFMmWd011EQsxbxbqfBl4COhvG/pNz7vunrXcLsNP/eh/wVf97U3TVj1LNl+nNxJv1tCIiG8qKZu5mNgj8KvC1Fax+G/BNV/Mk0G1m286jxlXpTtcCfXqx2KynFBHZcFbalvkD4LPA6b2OL/itly+bWcIfGwAON6wz5o8tYWZ3m9mImY1MTk6utu4z6krrFAQiIu8Y7mb2UeCYc273aXfdB/wC8F6gF/i91Tyxc+5+59ywc264v79/NQ89q27/tL/TCncRCbGVzNzfD3zMzA4B3wU+aGbfds6N+62XAvBnwPX++keA7Q2PH/THmqLelplZVLiLSHi9Y7g75+5zzg0654aAO4DHnXP/ut5HNzMDbgf2+Q95BLjT32vmBmDGOTe+PuW/Xf2CHeq5i0iYrWZvmdM9aGb9gAF7gE/5438H3AqMAovAJ86rwlXqTNb+SWrLiEiYrSrcnXNPAE/4yx88wzoOuOd8CztXXjRCR9JjWm0ZEQmxwB2hCtCd1pkhRSTcAhnumbjHfEGnIBCR8ApmuCc8csVKq8sQEWmZQIZ7Oh5loaiZu4iEVyDDPRP3WCxo5i4i4RXIcE8nNHMXkXALZrjHoyyq5y4iIRbIcM/EPRY1cxeREAtkuKfjHvlSlUrVtboUEZGWCGS4ZxJRAM3eRSS0AhnuqXg93NV3F5FwCmS4Z+K1U+Ys6ChVEQmpQIZ7WjN3EQm5QIZ7JlGbuSvcRSSsAhnu9Z67DmQSkbAKZLjXe+46BYGIhFUgwz2tmbuIhFwgw73ec9dpf0UkrAIZ7pq5i0jYBTLcE16EiKnnLiLhFchwNzMycU8zdxEJrUCGO9TO6a6Zu4iEVWDDPRP3WCwp3EUknAIb7ql4lEWdW0ZEQiqw4a6eu4iEWWDDPZ3QpfZEJLwCG+6ZuKdT/opIaAU23NPxqI5QFZHQCnS4LyjcRSSkghvuCU/XUBWR0ApsuGfiUUoVR7FcbXUpIiJNF9hwT9fP6a7Zu4iEUIDDXddRFZHwCm64JzRzF5HwCmy4Z+rndNfJw0QkhAIb7vWeu05BICJhFNhwzyT8nrtm7iISQoENd11qT0TCbMXhbmZRM3vWzP7Gv32RmT1lZqNm9j0zi/vjCf/2qH//0PqUfnb1toxOQSAiYbSamfungZcabn8R+LJz7lLgJPBJf/yTwEl//Mv+ek2XOdVzV7iLSPisKNzNbBD4VeBr/m0DPgh831/lAeB2f/k2/zb+/R/y12+qVH0/d50ZUkRCaKUz9z8APgvUj+XvA6adc/XkHAMG/OUB4DCAf/+Mv/4SZna3mY2Y2cjk5OQ5ln9mcS9CPBrRzF1EQukdw93MPgocc87tXssnds7d75wbds4N9/f3r+WPPqV2wQ7N3EUkfLwVrPN+4GNmdiuQBDqBPwS6zczzZ+eDwBF//SPAdmDMzDygC5ha88pXoHbBDs3cRSR83nHm7py7zzk36JwbAu4AHnfO/RbwE+Bf+KvdBfzAX37Ev41//+POObemVa9QOq6Zu4iE0/ns5/57wGfMbJRaT/3r/vjXgT5//DPAvedX4rlLJzz13EUklFbSljnFOfcE8IS/fBC4fpl18sCvr0Ft5y0di2pvGREJpcAeoQq1UxBo5i4iYRTocE/HPXLquYtICAU63DVzF5GwCnS4ZxMes7lSq8sQEWm6QId7TyZOoVzVycNEJHSCHe7pOAAnF4strkREpLlCEe4nFhTuIhIugQ733kwt3KcX1XcXkXAJdLj3pGMAnFBbRkRCJtDh3pdNAHB8rtDiSkREmivQ4d6TjhH3Ihydzbe6FBGRpgp0uJsZWzuTTCjcRSRkAh3uAFu7kozPKNxFJFyCH+6dSbVlRCR0Ah/u2/yZe7XakuuFiIi0RODDfWhThmK5ypHpXKtLERFpmsCH++VbOwDYPzHX4kpERJon8OG+c3MWgFeOKdxFJDwCH+4dyRibsgleP77Y6lJERJom8OEOMNSX5tDUQqvLEBFpmlCE+46+NG+c0MxdRMIjFOE+1JdhfCZPvqSLdohIOIQi3C/sSwNo9i4ioRGScM8AcOi4+u4iEg6hCPchf+b+rSdfb3ElIiLNEYpw707HSXgRnjs8TaGsvruIBF8owh3gT377Pczmyzw0MtbqUkRE1l1owv2my/q5Ylsnv/+j/fxw3wTO6URiIhJcoQl3M+NLv34tfZk4n/r2bnb918d49o2TVHS2SBEJINsIM9jh4WE3MjLSlOcqV6r8+wef4bEXj77tvp50jI+/e5BNHXHm82U2dyToSMZ4+tAJZnIlrh7oYrAnxd6xGbZ21k4l/Ozhk6RiUe64fgfXD/Xy0vgsl27OcmhqgVeOzjN8YQ+ZhMfLE7P86IWjXNqf5c5/ciHZpMd8vsx0rsRcvkRfNkG5UuXliTk2ZRP0ZuJs7Uzy5GtTzOfLXDPQxUBPinypwv8bneLA5DzbupIsFiv86IUJfunyzcSixmBPioQXZUtnksMnFvnb58e5uD9DrljhV67YwkBPioOTC7w5neP4fIGL+zNs7kgC8PrUIs8fmSHuRfizn77GBd0pOlMe/+p9O3jt+CILhTI96RjDQ714EcMMnnrtBO+7qI/NHQmiESMT9/jZgeNMLRR5fWqBXKlCdyrONYNdbO5IMNSX4cDkPLFohP6OBCcWipQqVaIRY2q+SF82ztauJAkvymyuxLG5Am9O5xge6mGhUKFQrjDQnSIWjfDK0TmeeWOaG3duYjZfwotEeHF8lkKpQrnquKQ/S39HgomZPIlYhNlcmcdenCBixqVbsvRl4mQTMbpSMXozcY7N5fnbveP89d43+dAvbGGwN8X4dJ5tXUnevaOHC/vSRCPG1q4kzkHCixCNGPsn5pgvlDk+X2B7T5qL+zM4wFVhOldkoDuFF40wNV9g35uzAFy+pYPFYpk3p/Ps3JKlKxXjjROLlCpVACZm8gxtyjAxk6dcdUQMomYM9qSZzZfY3JEgnfCYy5eYzZWZyZXYlI0DtYlMbzrO5HyBF8dniUWMD1+1lblCmbl8iUrVYRjRqBGP1uZ3i8UyHckYPztwnErV0d+RYPehk+zc0sGV2zrpzcYplqunLjo/tVCkUK4yny8zXygxNV/kim2dRCKGFzH6swkWSxVyxQrd6RgRM/7xwBTv2t4FgBcxUrEo5arj8IlFzIyZXIl0PEo8GiGT8CiUKywUKkQMZvNlZnJFLunPkkl4bMommC+UOTFfJO5F6Eh6VJwjHo3w9KETzOXL3HRZP68cnaNUcVSdoycd57mxafoycQ5MznNwcoHbdg2woy9NVyrGQqHM+EyehUKZge4U6USUqfkiL43PEjHj+ot66cvGmcuXiZqRjEU5uVikXHHMF8q8OZ3j2cMnuXhTlncNdtGZivHim7NMLRRZKJTZ1pXkmsEujs8V2bklS65YIV+usLUziZmdU56Z2W7n3PCy94Ut3AGcczw0cpixkzm+v3tMV2oSWaGEF6FcdWvyF68ZnGv8xKMRiv5/hO3u7hsv5j/fesU5PfZs4e6dV1Vtysz4zffuAOA/3Hw55UqVwydzvHp0jqpzHJpaZEtngm8/+QYdSY+rLujk1aPzxLwIk3MFdvSmySY8OpMeN13ez0yuxOMvH2NzR5K/fGaMmy7rJ2K1mW2+VCEV8+jLxpmYyVMsV+lIeszly1y6OcvzR2bIJDxmckWePnSSawa62LW9mzdOLBKLRpicy+NFIvRl45QqVRJelBMLRQBmciX6/dlwJhHl6GyeH790jIpz/OZ7t/PXz43z/kv6SMejPPXaCSZm8+zcnGXv2Ay3XL2VfKn2y1GqVDEz9h+dZagvQ8SMawa6uPKCTvYcnubqgS4eGjlMLFKbrWQTHvlyhVQsyvH5Ihd0J4mYMb1YojdTmzFWqw4zOLlQolCu0JOJM3psnmsHu8mVKhTKVTZl47wxtcjF/Rku6E5x5GSOJ16Z5KbL+knHoxyfLxAx440Ti1y0KcPu109yw8V9pGJRskmPgl9/V8rjteMLxKIRDp9cJOFFufmqLZQqVf7i54e56oJOtnQmeX5shqsHuhjyT0cxPpMnk4gymytzcrHIpmyCqwdqf2EUylWm5gtkEh5HZ/P844EputIxBrtT7HtzFi9iOODSzVm6UzE6UzH+6CejDPak2NaVoicdZy5fYmI2T382QdU54l5tljwxW+C6Hd1MzhV48Kk32NGb5tLNWbZ1Jak6qFYdY9OLDF/Yy/H5Apf0Z6lUHRU/Ccenc3Sn45jVTmV9SX+WYqVKsVzljROL7OhNs1Aoky9X2dqZ4ODkAj2ZOH3ZOH/yDwe5473bT/0ebOms/fX0k/3HuPWabaRiUaYXS0AtyGfzZRJehE5/ZpwrVknFI3QkY/z01eM8f2SGO67fzmyuxGBPmrGTOXLFMslYlM2dSX42epzLt3aQSXjsHZumIxnj+HyBjmSMawe7cA5e9k/HXa5WeddgN51J79R/IicXS6RiUX74wgQzi0Vi0Qi/dHk/+VKV7nSMXLFC3IswemyelyfmeM+FPewdm+afXrKJcrXK9GKJ+UKZnZs7ODpX+/27YmsHh0/m2D8xx64d3Rw4Ns/23jRbO5M89uJRrrqgk23dSRYKFa67sAcDskmPfWMzTC0U6UrFeHM6R65U4aXxWW7fNcB8sTbb/9noFHEvwvBQD0dn88SiETZlE7w4PkvCi7B3bIaOpEd3KsYV2zr52k9f49Zrtq1PzoVx5i4iEgRnm7mH5gNVEZEwUbiLiASQwl1EJIAU7iIiAaRwFxEJIIW7iEgAKdxFRAJI4S4iEkAb4iAmM5sEzvVKGpuA42tYzlrZqHXBxq1Nda2O6lqdINZ1oXOuf7k7NkS4nw8zGznTEVqttFHrgo1bm+paHdW1OmGrS20ZEZEAUriLiARQEML9/lYXcAYbtS7YuLWprtVRXasTqrravucuIiJvF4SZu4iInEbhLiISQG0d7mb2ETPbb2ajZnZvk597u5n9xMxeNLMXzOzT/vjnzeyIme3xv25teMx9fq37zezD61jbITN73n/+EX+s18weM7NX/e89/riZ2Vf8uvaa2XXrVNPlDdtkj5nNmtnvtmJ7mdk3zOyYme1rGFv19jGzu/z1XzWzu9aprv9uZi/7z/2wmXX740NmlmvYbn/c8Jj3+K//qF/7uV2g8+x1rfp1W+vf1zPU9b2Gmg6Z2R5/vJnb60zZ0Nz3mHOuLb+AKHAAuBiIA88BVzbx+bcB1/nLHcArwJXA54H/uMz6V/o1JoCL/Nqj61TbIWDTaWP/DbjXX74X+KK/fCvwfwADbgCeatJrNwFc2IrtBdwIXAfsO9ftA/QCB/3vPf5yzzrUdTPg+ctfbKhrqHG9037Oz/1aza/9lnWoa1Wv23r8vi5X12n3fwn4Ly3YXmfKhqa+x9p55n49MOqcO+icKwLfBW5r1pM758adc8/4y3PAS8DAWR5yG/Bd51zBOfcaMErt39AstwEP+MsPALc3jH/T1TwJdJvZ+lzU8S0fAg445852VPK6bS/n3P8FTizzfKvZPh8GHnPOnXDOnQQeAz6y1nU55x51zpX9m08Cg2f7GX5tnc65J10tIb7Z8G9Zs7rO4kyv25r/vp6tLn/2/RvAX5ztZ6zT9jpTNjT1PdbO4T4AHG64PcbZw3XdmNkQ8G7gKX/od/w/r75R/9OL5tbrgEfNbLeZ3e2PbXHOjfvLE8CWFtRVdwdLf+lavb1g9dunFdvt31Kb4dVdZGbPmtk/mNkv+mMDfi3NqGs1r1uzt9cvAkedc682jDV9e52WDU19j7VzuG8IZpYF/hL4XefcLPBV4BJgFzBO7U/DZvuAc+464BbgHjO7sfFOf4bSkn1gzSwOfAz43/7QRtheS7Ry+5yJmX0OKAMP+kPjwA7n3LuBzwDfMbPOJpa04V630/xLlk4gmr69lsmGU5rxHmvncD8CbG+4PeiPNY2Zxai9eA865/4KwDl31DlXcc5VgT/lrVZC0+p1zh3xvx8DHvZrOFpvt/jfjzW7Lt8twDPOuaN+jS3fXr7Vbp+m1Wdm/wb4KPBbfijgtz2m/OXd1PrZl/k1NLZu1qWuc3jdmrm9PODXgO811NvU7bVcNtDk91g7h/vTwE4zu8ifDd4BPNKsJ/d7el8HXnLO/Y+G8cZ+9ceB+if5jwB3mFnCzC4CdlL7IGet68qYWUd9mdoHcvv8569/2n4X8IOGuu70P7G/AZhp+NNxPSyZUbV6ezVY7fb5EXCzmfX4LYmb/bE1ZWYfAT4LfMw5t9gw3m9mUX/5Ymrb56Bf26yZ3eC/R+9s+LesZV2rfd2a+fv6K8DLzrlT7ZZmbq8zZQPNfo+dz6fCrf6i9inzK9T+F/5ck5/7A9T+rNoL7PG/bgW+BTzvjz8CbGt4zOf8Wvdznp/In6Wui6ntifAc8EJ9uwB9wI+BV4G/B3r9cQP+yK/reWB4HbdZBpgCuhrGmr69qP3nMg6UqPUxP3ku24daD3zU//rEOtU1Sq3vWn+P/bG/7j/3X989wDPAP2v4OcPUwvYA8L/wj0Rf47pW/bqt9e/rcnX5438OfOq0dZu5vc6UDU19j+n0AyIiAdTObRkRETkDhbuISAAp3EVEAkjhLiISQAp3EZEAUriLiASQwl1EJID+P1G+e7lQgfZZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    y = model(x)\n",
    "    loss = loss_fn(y,yt)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    losses+=[loss.item()]\n",
    "    print( f\"loss = {loss}\")\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRlkcpT0D-a1"
   },
   "source": [
    "## MNIST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "F4GfdMRhD-a1"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "referenced_widgets": [
      "7d17bdd53a0a4e1cba2ec1570f49e5e3",
      "8b5258e983f64de98263d2f36acc8308",
      "026cdcd4256b43528a85d9ab74259ab5",
      "0df2f617ad56455794e0e248f73f7032",
      "23b10fa9e2fd49c688f20fd8471ff54b",
      "57429ce3f3174238af7e57f568db94d3",
      "b4a5bab085f749c4b5b79075e2bbf78c",
      "8005cf80cae5436f8b6f4515527a9951",
      "a028a27846634a1da4cb9a0f627de164",
      "260f360ef21b40118ade200f8e301ae3",
      "5b67b220da7541ea9fea3d27fc9eb523",
      "fe1d5284f4294f15a4a24fcb4feb273f",
      "cddf54fd0a4241a5b9f5df91d942ceb7",
      "5af755ce64014f7a8c4c81394f4d96c8",
      "204e64d21e834143ab8452d8090a10e7",
      "8a1f2e0286514502872c058ce568a04c",
      "7f4a4bf476444dd789b94717f754eadd",
      "612777c7085d4d52903bfb54802ec360",
      "6a1f073cbae84b0f85cbaefbb686666c",
      "125f26e42ef54abb984eccd6899ca04b",
      "c1bf91c1e85645beb03dbef9285a5fcc",
      "42d39cfd1050484681b0d8ed23e4870e",
      "0a220811b00f4d60abb10557896d55cb",
      "849e90f1371643d89fce6708f0ec8729",
      "0a7c5cd27cf44bd4a383388da1efd504",
      "12e6fcddb1d74f1384fa16a99103a7e3",
      "27fbdae72bbf4905b6ac348a3e6b3836",
      "d0bb26d990ef4f48821a27f3416dc1e7",
      "fa68d9165d774b7a8d6600abb5e928d9",
      "993570e142044735b9fa9f1364bee33c",
      "f20481f1a19f4a7498e304e3bb352f47",
      "551a2faae1704392878c30e47eef72c2"
     ]
    },
    "id": "fyQ4gP46D-a3",
    "outputId": "5064957b-4d81-48ec-fe9f-e52b8c8ba162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d17bdd53a0a4e1cba2ec1570f49e5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a028a27846634a1da4cb9a0f627de164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4a4bf476444dd789b94717f754eadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7c5cd27cf44bd4a383388da1efd504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "data = MNIST(\".\",download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wdfX2XnGD-a4",
    "outputId": "da343ead-3b98-4fd9-dec5-460a71a08fa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "id": "s7fwSvMkD-a5",
    "outputId": "d571aef5-d714-4175-9aa9-b901156a39a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABE0lEQVR4nM2Pv0sCARTHP4lzQ1lQR0uFQj/OqTVqbGlsaKmGtiaHgrg/oE1ojMQhqCiI2oLWIGwSKlIq8IoISYJuU8+vLWd34rlG3+W99/28x+MLf6Hx1+vAFPVbcwHiI3YoTF7FgOZNAPb8dm8GR7nb6n095Nt6Q9vREB9g8kPH3Rhb0nSHGfFqgpNCt0OqIYctzbvq73RbUaqViW8As5fl2O5TObgzXEsDfTOZL0nS3eXFkA/j9YMonEvN5/zm4kq+oocln74rwazjPKYGAZiTrGDOoplS1ptGT1We8qF5KElnGcswjGSm6O61JTPtT1ee3JfVtigAazsDNAr74GTpVLqm0kYkBACQsOzSWDf4D/QDtJlp6Aq8FIcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7EFBA0C173C8>"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "img,y = data[np.random.randint(1,60000)]\n",
    "print(y)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "3giZTnRiD-a-",
    "outputId": "94da1215-cd79-4474-ddbe-db03f5ab36fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_data[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "nsZHdAMlD-a_",
    "outputId": "d59bb5e1-9fb8-4f44-d59c-23323481bcec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_labels[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROmpaSMVD-bA"
   },
   "source": [
    "### MNIST Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "qHhKarpfD-bB"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "E8Q59QCED-bC"
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "ehneQZatD-bG",
    "outputId": "453d29ba-4716-4000-dfc8-c6f1f57151dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.choice(range(len(data.train_data)),1000)\n",
    "x = data.train_data[sample].reshape(1000,-1).float()/255\n",
    "yt = data.train_labels[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ucZS9UPAD-bJ",
    "outputId": "36167fe0-0fa4-45b9-9281-2f1a5255421c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 784]), torch.Size([1000]))"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "jdOxW-tYD-bK"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "mMtNhgaED-bL",
    "outputId": "d372c14b-1744-4a5c-fc97-e8683a92dcc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    sample = np.random.choice(range(len(data.train_data)),1000)\n",
    "    x = data.train_data[sample].reshape(1000,-1).float()/255\n",
    "    yt = data.train_labels[sample]\n",
    "    \n",
    "    y = model(x)\n",
    "    loss = loss_fn(y,yt)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    losses+=[loss.item()]\n",
    "    #print( f\"loss = {loss}\")\n",
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "1BAXeaKHD-bM",
    "outputId": "72947ff9-1a2e-4fb5-9397-8f08482fc47e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "x_test = data.train_data[-1000:].reshape(1000,-1).float()/255\n",
    "y_test = data.train_labels[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "5VXFOBCjD-bO"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "tt0c-JhpD-bP",
    "outputId": "6b7bf58e-aa4c-4273-cb5a-de02f234f6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \", (y_pred.argmax(dim=1) == y_test).sum().float().item()/1000.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY6m7c0qD-bQ"
   },
   "source": [
    "## Course Conclusion\n",
    "\n",
    "By now you should have a sufficient introduction to the various ways one can use python for scientific computing. The best way to learn more is to start using python for whatever project you are working on. Only practice will make you comfortable with using python.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "pDnSshCXD-ZL",
    "2JDTirUfD-Zf",
    "vICVTE1wD-Zq",
    "wDNQLaL6D-Zu",
    "hNbj9oDlD-aS",
    "3kRdaQe6D-ab",
    "5t7iYj2eD-an",
    "tRlkcpT0D-a1",
    "ROmpaSMVD-bA",
    "VY6m7c0qD-bQ"
   ],
   "name": "Lecture_8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "026cdcd4256b43528a85d9ab74259ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57429ce3f3174238af7e57f568db94d3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_23b10fa9e2fd49c688f20fd8471ff54b",
      "value": 1
     }
    },
    "0a220811b00f4d60abb10557896d55cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a7c5cd27cf44bd4a383388da1efd504": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27fbdae72bbf4905b6ac348a3e6b3836",
       "IPY_MODEL_d0bb26d990ef4f48821a27f3416dc1e7"
      ],
      "layout": "IPY_MODEL_12e6fcddb1d74f1384fa16a99103a7e3"
     }
    },
    "0df2f617ad56455794e0e248f73f7032": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8005cf80cae5436f8b6f4515527a9951",
      "placeholder": "​",
      "style": "IPY_MODEL_b4a5bab085f749c4b5b79075e2bbf78c",
      "value": " 9920512/? [00:05&lt;00:00, 1961217.11it/s]"
     }
    },
    "125f26e42ef54abb984eccd6899ca04b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_849e90f1371643d89fce6708f0ec8729",
      "placeholder": "​",
      "style": "IPY_MODEL_0a220811b00f4d60abb10557896d55cb",
      "value": " 1654784/? [00:00&lt;00:00, 2020789.76it/s]"
     }
    },
    "12e6fcddb1d74f1384fa16a99103a7e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "204e64d21e834143ab8452d8090a10e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23b10fa9e2fd49c688f20fd8471ff54b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "260f360ef21b40118ade200f8e301ae3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27fbdae72bbf4905b6ac348a3e6b3836": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_993570e142044735b9fa9f1364bee33c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fa68d9165d774b7a8d6600abb5e928d9",
      "value": 1
     }
    },
    "42d39cfd1050484681b0d8ed23e4870e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "551a2faae1704392878c30e47eef72c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57429ce3f3174238af7e57f568db94d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5af755ce64014f7a8c4c81394f4d96c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b67b220da7541ea9fea3d27fc9eb523": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5af755ce64014f7a8c4c81394f4d96c8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cddf54fd0a4241a5b9f5df91d942ceb7",
      "value": 1
     }
    },
    "612777c7085d4d52903bfb54802ec360": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a1f073cbae84b0f85cbaefbb686666c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42d39cfd1050484681b0d8ed23e4870e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c1bf91c1e85645beb03dbef9285a5fcc",
      "value": 1
     }
    },
    "7d17bdd53a0a4e1cba2ec1570f49e5e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_026cdcd4256b43528a85d9ab74259ab5",
       "IPY_MODEL_0df2f617ad56455794e0e248f73f7032"
      ],
      "layout": "IPY_MODEL_8b5258e983f64de98263d2f36acc8308"
     }
    },
    "7f4a4bf476444dd789b94717f754eadd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6a1f073cbae84b0f85cbaefbb686666c",
       "IPY_MODEL_125f26e42ef54abb984eccd6899ca04b"
      ],
      "layout": "IPY_MODEL_612777c7085d4d52903bfb54802ec360"
     }
    },
    "8005cf80cae5436f8b6f4515527a9951": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "849e90f1371643d89fce6708f0ec8729": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a1f2e0286514502872c058ce568a04c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b5258e983f64de98263d2f36acc8308": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "993570e142044735b9fa9f1364bee33c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a028a27846634a1da4cb9a0f627de164": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b67b220da7541ea9fea3d27fc9eb523",
       "IPY_MODEL_fe1d5284f4294f15a4a24fcb4feb273f"
      ],
      "layout": "IPY_MODEL_260f360ef21b40118ade200f8e301ae3"
     }
    },
    "b4a5bab085f749c4b5b79075e2bbf78c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1bf91c1e85645beb03dbef9285a5fcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cddf54fd0a4241a5b9f5df91d942ceb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d0bb26d990ef4f48821a27f3416dc1e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_551a2faae1704392878c30e47eef72c2",
      "placeholder": "​",
      "style": "IPY_MODEL_f20481f1a19f4a7498e304e3bb352f47",
      "value": " 8192/? [00:02&lt;00:00, 3244.85it/s]"
     }
    },
    "f20481f1a19f4a7498e304e3bb352f47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa68d9165d774b7a8d6600abb5e928d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe1d5284f4294f15a4a24fcb4feb273f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a1f2e0286514502872c058ce568a04c",
      "placeholder": "​",
      "style": "IPY_MODEL_204e64d21e834143ab8452d8090a10e7",
      "value": " 32768/? [00:01&lt;00:00, 30167.25it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
